{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38f2b5b-c216-4c7f-a0fd-288d0d361417",
   "metadata": {},
   "source": [
    "STEP 1 — LOAD CRIME DATA + INITIAL INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7857e802-5fb4-4abd-a19d-7b4fa3835c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:39:49.257496Z",
     "start_time": "2025-12-05T02:39:49.249840Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288eda3-38c0-4c00-be05-b80278c48cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:44:58.443580Z",
     "start_time": "2025-12-05T02:44:48.419475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime data shape: (1923226, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14030083</td>\n",
       "      <td>JJ490890</td>\n",
       "      <td>11/15/2025 10:54:00 PM</td>\n",
       "      <td>051XX W BLOOMINGDALE AVE</td>\n",
       "      <td>0420</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>AGGRAVATED - KNIFE / CUTTING INSTRUMENT</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>04B</td>\n",
       "      <td>1141877.0</td>\n",
       "      <td>1911484.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>11/23/2025 03:42:58 PM</td>\n",
       "      <td>41.913178</td>\n",
       "      <td>-87.754211</td>\n",
       "      <td>(41.913177726, -87.754210718)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14030104</td>\n",
       "      <td>JJ490911</td>\n",
       "      <td>11/15/2025 10:49:00 PM</td>\n",
       "      <td>048XX W HENDERSON ST</td>\n",
       "      <td>4387</td>\n",
       "      <td>OTHER OFFENSE</td>\n",
       "      <td>VIOLATE ORDER OF PROTECTION</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1143465.0</td>\n",
       "      <td>1921833.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>11/23/2025 03:42:58 PM</td>\n",
       "      <td>41.941547</td>\n",
       "      <td>-87.748117</td>\n",
       "      <td>(41.941546843, -87.748117196)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14030070</td>\n",
       "      <td>JJ490877</td>\n",
       "      <td>11/15/2025 10:45:00 PM</td>\n",
       "      <td>009XX W 116TH ST</td>\n",
       "      <td>0560</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>08A</td>\n",
       "      <td>1171942.0</td>\n",
       "      <td>1827824.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>11/23/2025 03:42:58 PM</td>\n",
       "      <td>41.682996</td>\n",
       "      <td>-87.646216</td>\n",
       "      <td>(41.682995567, -87.646215535)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14030085</td>\n",
       "      <td>JJ490876</td>\n",
       "      <td>11/15/2025 10:43:00 PM</td>\n",
       "      <td>021XX N LONG AVE</td>\n",
       "      <td>0520</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>AGGRAVATED - KNIFE / CUTTING INSTRUMENT</td>\n",
       "      <td>SCHOOL - PUBLIC GROUNDS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>04A</td>\n",
       "      <td>1140035.0</td>\n",
       "      <td>1913783.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>11/23/2025 03:42:58 PM</td>\n",
       "      <td>41.919520</td>\n",
       "      <td>-87.760922</td>\n",
       "      <td>(41.919520368, -87.760921537)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14030065</td>\n",
       "      <td>JJ490870</td>\n",
       "      <td>11/15/2025 10:40:00 PM</td>\n",
       "      <td>005XX N LAWNDALE AVE</td>\n",
       "      <td>2017</td>\n",
       "      <td>NARCOTICS</td>\n",
       "      <td>MANUFACTURE / DELIVER - CRACK</td>\n",
       "      <td>ALLEY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1151626.0</td>\n",
       "      <td>1903280.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>11/23/2025 03:42:58 PM</td>\n",
       "      <td>41.890479</td>\n",
       "      <td>-87.718611</td>\n",
       "      <td>(41.890478932, -87.718610734)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case Number                    Date                     Block  \\\n",
       "0  14030083    JJ490890  11/15/2025 10:54:00 PM  051XX W BLOOMINGDALE AVE   \n",
       "1  14030104    JJ490911  11/15/2025 10:49:00 PM      048XX W HENDERSON ST   \n",
       "2  14030070    JJ490877  11/15/2025 10:45:00 PM          009XX W 116TH ST   \n",
       "3  14030085    JJ490876  11/15/2025 10:43:00 PM          021XX N LONG AVE   \n",
       "4  14030065    JJ490870  11/15/2025 10:40:00 PM      005XX N LAWNDALE AVE   \n",
       "\n",
       "   IUCR   Primary Type                              Description  \\\n",
       "0  0420        BATTERY  AGGRAVATED - KNIFE / CUTTING INSTRUMENT   \n",
       "1  4387  OTHER OFFENSE              VIOLATE ORDER OF PROTECTION   \n",
       "2  0560        ASSAULT                                   SIMPLE   \n",
       "3  0520        ASSAULT  AGGRAVATED - KNIFE / CUTTING INSTRUMENT   \n",
       "4  2017      NARCOTICS            MANUFACTURE / DELIVER - CRACK   \n",
       "\n",
       "      Location Description  Arrest  Domestic  ...  Ward  Community Area  \\\n",
       "0                RESIDENCE    True      True  ...  37.0            25.0   \n",
       "1                APARTMENT    True      True  ...  31.0            15.0   \n",
       "2                RESIDENCE   False      True  ...  21.0            53.0   \n",
       "3  SCHOOL - PUBLIC GROUNDS   False     False  ...  36.0            19.0   \n",
       "4                    ALLEY    True     False  ...  27.0            23.0   \n",
       "\n",
       "   FBI Code  X Coordinate Y Coordinate  Year              Updated On  \\\n",
       "0       04B     1141877.0    1911484.0  2025  11/23/2025 03:42:58 PM   \n",
       "1        26     1143465.0    1921833.0  2025  11/23/2025 03:42:58 PM   \n",
       "2       08A     1171942.0    1827824.0  2025  11/23/2025 03:42:58 PM   \n",
       "3       04A     1140035.0    1913783.0  2025  11/23/2025 03:42:58 PM   \n",
       "4        18     1151626.0    1903280.0  2025  11/23/2025 03:42:58 PM   \n",
       "\n",
       "    Latitude  Longitude                       Location  \n",
       "0  41.913178 -87.754211  (41.913177726, -87.754210718)  \n",
       "1  41.941547 -87.748117  (41.941546843, -87.748117196)  \n",
       "2  41.682996 -87.646216  (41.682995567, -87.646215535)  \n",
       "3  41.919520 -87.760922  (41.919520368, -87.760921537)  \n",
       "4  41.890479 -87.718611  (41.890478932, -87.718610734)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "CRIME_KEY = \"Crimes_2018_to_Present.csv\"\n",
    "bucket = \"group-6-chicago-crime-data\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "CRIME_KEY = \"raw/Crimes_2018_to_Present.csv\"\n",
    "crime_df = pd.read_csv(f\"s3://{bucket}/{CRIME_KEY}\", low_memory=False)\n",
    "print(\"Crime data shape:\", crime_df.shape)\n",
    "crime_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d909e992-d032-4837-b848-74abb960be56",
   "metadata": {},
   "source": [
    "Parse ProQuest TXT → article-level news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a511bb6-1a3c-44bb-92bb-6bbc734aa5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:41:11.708811Z",
     "start_time": "2025-12-05T02:40:58.982672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local TXT files found: 31\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (22).txt\n",
      "Parsed  539 articles from ProQuestDocuments-2025-11-25 (18).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (14).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (15).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (19).txt\n",
      "Parsed  502 articles from ProQuestDocuments-2025-11-25 (23).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (28).txt\n",
      "Parsed  508 articles from ProQuestDocuments-2025-11-25 (12).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (32).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (24).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (7).txt\n",
      "Parsed  514 articles from ProQuestDocuments-2025-11-25 (6).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (25).txt\n",
      "Parsed    6 articles from ProQuestDocuments-2025-11-25 (33).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (13).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (29).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (10).txt\n",
      "Parsed  502 articles from ProQuestDocuments-2025-11-25 (9).txt\n",
      "Parsed  558 articles from ProQuestDocuments-2025-11-25 (5).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (26).txt\n",
      "Parsed  503 articles from ProQuestDocuments-2025-11-25 (30).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (31).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (27).txt\n",
      "Parsed  570 articles from ProQuestDocuments-2025-11-25 (4).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (8).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (11).txt\n",
      "Parsed  545 articles from ProQuestDocuments-2025-11-25 (3).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (20).txt\n",
      "Parsed  502 articles from ProQuestDocuments-2025-11-25 (16).txt\n",
      "Parsed  531 articles from ProQuestDocuments-2025-11-25 (17).txt\n",
      "Parsed  501 articles from ProQuestDocuments-2025-11-25 (21).txt\n",
      "\n",
      "NEWS raw parsed shape: (15299, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationDateRaw</th>\n",
       "      <th>DocumentType</th>\n",
       "      <th>Subject</th>\n",
       "      <th>FullText</th>\n",
       "      <th>RawBlock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 dead, 2 hurt after stolen vehicle hits house...</td>\n",
       "      <td>Fry, Paige</td>\n",
       "      <td>Dec 15, 2019</td>\n",
       "      <td>News</td>\n",
       "      <td>Fires; Fatalities; Automobile theft</td>\n",
       "      <td>A teenage boy was killed and two other teenage...</td>\n",
       "      <td>1 dead, 2 hurt after stolen vehicle hits house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrats' impeachment of Trump is way too thin</td>\n",
       "      <td>Kass, John</td>\n",
       "      <td>Dec 15, 2019</td>\n",
       "      <td>News</td>\n",
       "      <td>Extortion; Impeachment; Scandals; Candidates</td>\n",
       "      <td>Where did the Trump impeachment go?\\nWhen Hous...</td>\n",
       "      <td>Democrats' impeachment of Trump is way too thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nearly 1,000 volunteers help hang lights down ...</td>\n",
       "      <td>Williams-Harris, Deanese</td>\n",
       "      <td>Dec 14, 2019</td>\n",
       "      <td>News</td>\n",
       "      <td>Community; Trauma; Holiday decorations</td>\n",
       "      <td>Community activists from My Block, My Hood, My...</td>\n",
       "      <td>Nearly 1,000 volunteers help hang lights down ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 teen dead, 2 injured after stolen vehicle cr...</td>\n",
       "      <td>Fry, Paige</td>\n",
       "      <td>Dec 14, 2019</td>\n",
       "      <td>News</td>\n",
       "      <td>Fatalities; Automobile theft</td>\n",
       "      <td>A teenage boy was killed and two other teenage...</td>\n",
       "      <td>1 teen dead, 2 injured after stolen vehicle cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VOICE OF THE PEOPLE</td>\n",
       "      <td>None</td>\n",
       "      <td>Dec 14, 2019</td>\n",
       "      <td>News</td>\n",
       "      <td>Agreements; Arbitration; Judaism; Long term he...</td>\n",
       "      <td>Judaism is not a nationality\\nAs a Jew, I am h...</td>\n",
       "      <td>VOICE OF THE PEOPLE\\n\\nhttps://www.proquest.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  1 dead, 2 hurt after stolen vehicle hits house...   \n",
       "1    Democrats' impeachment of Trump is way too thin   \n",
       "2  Nearly 1,000 volunteers help hang lights down ...   \n",
       "3  1 teen dead, 2 injured after stolen vehicle cr...   \n",
       "4                                VOICE OF THE PEOPLE   \n",
       "\n",
       "                     Author PublicationDateRaw DocumentType  \\\n",
       "0                Fry, Paige       Dec 15, 2019         News   \n",
       "1                Kass, John       Dec 15, 2019         News   \n",
       "2  Williams-Harris, Deanese       Dec 14, 2019         News   \n",
       "3                Fry, Paige       Dec 14, 2019         News   \n",
       "4                      None       Dec 14, 2019         News   \n",
       "\n",
       "                                             Subject  \\\n",
       "0                Fires; Fatalities; Automobile theft   \n",
       "1       Extortion; Impeachment; Scandals; Candidates   \n",
       "2             Community; Trauma; Holiday decorations   \n",
       "3                       Fatalities; Automobile theft   \n",
       "4  Agreements; Arbitration; Judaism; Long term he...   \n",
       "\n",
       "                                            FullText  \\\n",
       "0  A teenage boy was killed and two other teenage...   \n",
       "1  Where did the Trump impeachment go?\\nWhen Hous...   \n",
       "2  Community activists from My Block, My Hood, My...   \n",
       "3  A teenage boy was killed and two other teenage...   \n",
       "4  Judaism is not a nationality\\nAs a Jew, I am h...   \n",
       "\n",
       "                                            RawBlock  \n",
       "0  1 dead, 2 hurt after stolen vehicle hits house...  \n",
       "1  Democrats' impeachment of Trump is way too thi...  \n",
       "2  Nearly 1,000 volunteers help hang lights down ...  \n",
       "3  1 teen dead, 2 injured after stolen vehicle cr...  \n",
       "4  VOICE OF THE PEOPLE\\n\\nhttps://www.proquest.co...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3, os\n",
    "\n",
    "# If not already created earlier:\n",
    "# s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "prefix = \"raw/news/\"   # adjust if your path is different\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "contents = resp.get(\"Contents\", [])\n",
    "txt_keys = [o[\"Key\"] for o in contents if o[\"Key\"].lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Total S3 objects under\", prefix, \":\", len(contents))\n",
    "print(\"TXT files found:\", len(txt_keys))\n",
    "print(\"First 5 keys:\")\n",
    "for k in txt_keys[:5]:\n",
    "    print(\"  \", k)\n",
    "\n",
    "# Downloaded locally into news_local (only if not already there)\n",
    "os.makedirs(\"news_local\", exist_ok=True)\n",
    "\n",
    "for key in txt_keys:\n",
    "    local_name = os.path.basename(key)\n",
    "    local_path = os.path.join(\"news_local\", local_name)\n",
    "    if not os.path.exists(local_path):\n",
    "        print(\"Downloading:\", key, \"->\", local_path)\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "\n",
    "print(\"Done. Local TXT files:\", len(os.listdir(\"news_local\")))\n",
    "import os, re, glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Helper: extract multi-line field safely\n",
    "# -----------------------------------------------------------\n",
    "def extract_field(block, field_name):\n",
    "    \"\"\"\n",
    "    Extracts a metadata field like 'Title:' or 'Publication date:'.\n",
    "\n",
    "    Rule:\n",
    "    - Capture everything after \"FieldName:\"\n",
    "    - Stop when we hit the next field label or the end of block\n",
    "    \"\"\"\n",
    "    pattern = rf\"{field_name}\\s*:\\s*(.*?)(?=\\n[A-Za-z ]+\\s*:|\\Z)\"\n",
    "    match = re.search(pattern, block, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Final parsing function\n",
    "# -----------------------------------------------------------\n",
    "def parse_proquest_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Split articles by line of underscores\n",
    "    blocks = re.split(r\"_+\\s*\\n\", text)\n",
    "\n",
    "    articles = []\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if len(block) < 50:\n",
    "            continue\n",
    "\n",
    "        # Extract EXACT required fields\n",
    "        title  = extract_field(block, \"Title\")\n",
    "        author = extract_field(block, \"Author\")\n",
    "        pubdate = extract_field(block, \"Publication date\")\n",
    "        doctype = extract_field(block, \"Document type\")\n",
    "        subject = extract_field(block, \"Subject\")\n",
    "        fulltext = extract_field(block, \"Full text\")\n",
    "\n",
    "        # Title fallback (never skip)\n",
    "        if not title:\n",
    "            first_line = block.splitlines()[0].strip()\n",
    "            title = first_line[:150]\n",
    "\n",
    "        # Full text fallback (never missing)\n",
    "        if not fulltext:\n",
    "            # full article minus metadata\n",
    "            lines = block.splitlines()\n",
    "            fulltext = \"\\n\".join(lines).strip()\n",
    "\n",
    "        articles.append({\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"PublicationDateRaw\": pubdate,\n",
    "            \"DocumentType\": doctype,\n",
    "            \"Subject\": subject,\n",
    "            \"FullText\": fulltext,\n",
    "            \"RawBlock\": block\n",
    "        })\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Parse ALL files in news_local/\n",
    "# -----------------------------------------------------------\n",
    "all_articles = []\n",
    "\n",
    "txt_files = glob.glob(\"news_local/*.txt\")\n",
    "print(\"Local TXT files found:\", len(txt_files))\n",
    "\n",
    "for file in txt_files:\n",
    "    parsed = parse_proquest_file(file)\n",
    "    print(f\"Parsed {len(parsed):4d} articles from {os.path.basename(file)}\")\n",
    "    all_articles.extend(parsed)\n",
    "\n",
    "news_df = pd.DataFrame(all_articles)\n",
    "print(\"\\nNEWS raw parsed shape:\", news_df.shape)\n",
    "\n",
    "news_df.head()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3c491e-9ea6-4889-ae10-58b270111de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:46:24.709134Z",
     "start_time": "2025-12-05T02:46:17.193692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu --no-build-isolation --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7290daff-1c96-46c6-a94f-e1dd5d96dbd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:46:29.741543Z",
     "start_time": "2025-12-05T02:46:24.836691Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy boto3 sentence-transformers faiss-cpu plotly matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3f6962c436d8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:46:33.696576Z",
     "start_time": "2025-12-05T02:46:29.828866Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2e4573-90a1-4ae7-a859-f401e70f4315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:48:11.155564Z",
     "start_time": "2025-12-05T02:46:33.793542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithjagadeesan/Downloads/rag_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, gc, json, re, glob, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233c02cd10cb0376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:51:05.730666Z",
     "start_time": "2025-12-05T02:51:05.682960Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = \"cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "CRIME_CHUNKS_FILE = f\"{CACHE_DIR}/crime_chunks.jsonl\"\n",
    "NEWS_CHUNKS_FILE  = f\"{CACHE_DIR}/news_chunks.jsonl\"\n",
    "LINKS_FILE        = f\"{CACHE_DIR}/crime_news_links.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3348d813d39377a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:51:07.689994Z",
     "start_time": "2025-12-05T02:51:07.675148Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_safe(x):\n",
    "    if isinstance(x, (np.int64, np.int32, int)): return int(x)\n",
    "    if isinstance(x, (np.float64, np.float32, float)): return float(x)\n",
    "    if isinstance(x, pd.Timestamp): return x.isoformat()\n",
    "    return str(x)\n",
    "\n",
    "def write_jsonl(path, obj):\n",
    "    obj = {k: json_safe(v) if not isinstance(v, dict)\n",
    "           else {a: json_safe(b) for a,b in v.items()}\n",
    "           for k,v in obj.items()}\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a0e61848948cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:51:51.571881Z",
     "start_time": "2025-12-05T02:51:51.535339Z"
    }
   },
   "outputs": [],
   "source": [
    "class NarrativeIntelligenceSystem:\n",
    "\n",
    "    def __init__(self, crime_df, news_df, embedding_model=\"all-MiniLM-L6-v2\"):\n",
    "        print(\"Initializing system...\")\n",
    "        self.crime_df = crime_df.copy()\n",
    "        self.news_df  = news_df.copy()\n",
    "\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "\n",
    "        # Pre-clean\n",
    "        self.crime_df[\"Date\"] = pd.to_datetime(self.crime_df[\"Date\"])\n",
    "        self.news_df[\"PublicationDate\"] = pd.to_datetime(\n",
    "            self.news_df[\"PublicationDateRaw\"], errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "        print(\"Data ready.\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # CREATE CRIME CHUNKS\n",
    "    # ------------------------------------------------------------\n",
    "    def create_crime_chunks(self, min_crimes=5):\n",
    "        print(\" Creating crime chunks → JSONL\")\n",
    "\n",
    "        if os.path.exists(CRIME_CHUNKS_FILE):\n",
    "            os.remove(CRIME_CHUNKS_FILE)\n",
    "\n",
    "        g = self.crime_df.groupby([\"Primary Type\", \"Block\", self.crime_df[\"Date\"].dt.date])\n",
    "\n",
    "        for (ptype, block, day), grp in tqdm(g, total=len(g)):\n",
    "            if len(grp) < min_crimes:\n",
    "                continue\n",
    "\n",
    "            text = f\"\"\"\n",
    "Crime Report Summary\n",
    "Type: {ptype}\n",
    "Block: {block}\n",
    "Date: {day}\n",
    "Incidents: {len(grp)}\n",
    "Arrests: {grp['Arrest'].sum()}\n",
    "Latitude: {grp['Latitude'].mean()}\n",
    "Longitude: {grp['Longitude'].mean()}\n",
    "\"\"\"\n",
    "            metadata = {\n",
    "                \"primary_type\": ptype,\n",
    "                \"block\": block,\n",
    "                \"date\": str(day),\n",
    "                \"count\": len(grp)\n",
    "            }\n",
    "\n",
    "            write_jsonl(CRIME_CHUNKS_FILE, {\"text\": text, \"metadata\": metadata})\n",
    "\n",
    "        print(\"Crime chunks saved.\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # CREATE NEWS CHUNKS\n",
    "    # ------------------------------------------------------------\n",
    "    def create_news_chunks(self, max_len=1500):\n",
    "        print(\" Creating news chunks → JSONL\")\n",
    "\n",
    "        if os.path.exists(NEWS_CHUNKS_FILE):\n",
    "            os.remove(NEWS_CHUNKS_FILE)\n",
    "\n",
    "        for _, row in tqdm(self.news_df.iterrows(), total=len(self.news_df)):\n",
    "            text = f\"Title: {row['Title']}\\n\\n{row['FullText']}\"\n",
    "            metadata = {\n",
    "                \"title\": str(row['Title']),\n",
    "                \"date\": str(row[\"PublicationDate\"]),\n",
    "                \"subject\": str(row.get(\"Subject\"))\n",
    "            }\n",
    "\n",
    "            write_jsonl(NEWS_CHUNKS_FILE, {\n",
    "                \"text\": text[:max_len],\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "        print(\"News chunks saved.\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # DETERMINISTIC LINKING ENGINE\n",
    "    # ------------------------------------------------------------\n",
    "    def build_crime_news_links(self, days_window=3):\n",
    "        print(\"Building deterministic crime ↔ news links\")\n",
    "\n",
    "        if os.path.exists(LINKS_FILE):\n",
    "            os.remove(LINKS_FILE)\n",
    "\n",
    "        for _, crime in tqdm(self.crime_df.iterrows(), total=len(self.crime_df)):\n",
    "            date = crime[\"Date\"]\n",
    "            ptype = crime[\"Primary Type\"]\n",
    "            block = crime[\"Block\"]\n",
    "\n",
    "            window = self.news_df[\n",
    "                (self.news_df[\"PublicationDate\"] >= date - pd.Timedelta(days=days_window)) &\n",
    "                (self.news_df[\"PublicationDate\"] <= date + pd.Timedelta(days=days_window))\n",
    "            ]\n",
    "\n",
    "            # block similarity (prefix matching)\n",
    "            simple_block = block.split()[1] if len(block.split()) > 1 else block\n",
    "            candidates = window[ window[\"FullText\"].str.contains(simple_block.split()[0], case=False, na=True) ]\n",
    "\n",
    "            # primary-type keyword match\n",
    "            candidates = candidates[candidates[\"FullText\"].str.contains(ptype.split()[0], case=False, na=True)]\n",
    "\n",
    "            for _, news in candidates.iterrows():\n",
    "                write_jsonl(LINKS_FILE, {\n",
    "                    \"crime_type\": ptype,\n",
    "                    \"crime_block\": block,\n",
    "                    \"crime_date\": str(date),\n",
    "                    \"news_title\": news[\"Title\"],\n",
    "                    \"news_date\": str(news[\"PublicationDate\"])\n",
    "                })\n",
    "\n",
    "        print(\"Deterministic links created.\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # SEMANTIC VECTOR INDEX (memory-safe)\n",
    "    # ------------------------------------------------------------\n",
    "    def build_vector_index(self, jsonl_file, output_index, batch_size=128):\n",
    "        print(f\"Building vector index: {output_index}\")\n",
    "\n",
    "        index = None\n",
    "        texts = []\n",
    "\n",
    "        # Streaming read\n",
    "        with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in tqdm(f):\n",
    "                obj = json.loads(line)\n",
    "                texts.append(obj[\"text\"])\n",
    "\n",
    "                if len(texts) >= batch_size:\n",
    "                    emb = self.model.encode(texts, convert_to_numpy=True, batch_size=16)\n",
    "                    if index is None:\n",
    "                        index = faiss.IndexFlatL2(emb.shape[1])\n",
    "                    index.add(emb.astype(\"float32\"))\n",
    "                    texts = []\n",
    "                    gc.collect()\n",
    "\n",
    "        # Remaining\n",
    "        if texts:\n",
    "            emb = self.model.encode(texts, convert_to_numpy=True, batch_size=16)\n",
    "            if index is None:\n",
    "                index = faiss.IndexFlatL2(emb.shape[1])\n",
    "            index.add(emb.astype(\"float32\"))\n",
    "\n",
    "        faiss.write_index(index, output_index)\n",
    "        print(\"Index saved:\", output_index)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # HYBRID RAG QUERY\n",
    "    # ------------------------------------------------------------\n",
    "    def rag_query(self, user_query, top_k=5):\n",
    "        print(\" Running Hybrid RAG Query...\")\n",
    "\n",
    "        q_emb = self.model.encode([user_query], convert_to_numpy=True)\n",
    "\n",
    "        # Load indices\n",
    "        crime_index = faiss.read_index(f\"{CACHE_DIR}/crime_index.faiss\")\n",
    "        news_index  = faiss.read_index(f\"{CACHE_DIR}/news_index.faiss\")\n",
    "\n",
    "        d_c, i_c = crime_index.search(q_emb, top_k)\n",
    "        d_n, i_n = news_index.search(q_emb, top_k)\n",
    "\n",
    "        # Load chunks\n",
    "        def read_chunk(file, idx):\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line_num, line in enumerate(f):\n",
    "                    if line_num == idx:\n",
    "                        return json.loads(line)\n",
    "\n",
    "        crime_chunks = [read_chunk(CRIME_CHUNKS_FILE, i) for i in i_c[0]]\n",
    "        news_chunks  = [read_chunk(NEWS_CHUNKS_FILE, i) for i in i_n[0]]\n",
    "\n",
    "        # Load deterministic links\n",
    "        links = []\n",
    "        with open(LINKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            for L in f:\n",
    "                links.append(json.loads(L))\n",
    "\n",
    "        return {\n",
    "            \"crime\": crime_chunks,\n",
    "            \"news\": news_chunks,\n",
    "            \"links\": links[:20]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe48a36ceca1bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:52:04.666744Z",
     "start_time": "2025-12-05T02:51:58.617387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.11.9)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "class NarrativeChatbot:\n",
    "\n",
    "    def __init__(self, api_key, system):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"models/gemini-pro-latest\")\n",
    "        self.system = system\n",
    "\n",
    "    def ask(self, query):\n",
    "        rag = self.system.rag_query(query)\n",
    "\n",
    "        context = \"\\n\\n\".join([\n",
    "            \"=== CRIME DATA ===\\n\" + \"\\n\".join(c[\"text\"] for c in rag[\"crime\"]),\n",
    "            \"=== NEWS DATA ===\\n\" + \"\\n\".join(n[\"text\"] for n in rag[\"news\"]),\n",
    "            \"=== LINKS FOUND ===\\n\" + \"\\n\".join(json.dumps(l) for l in rag[\"links\"])\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a Chicago crime-narrative analyst.\n",
    "\n",
    "User question:\n",
    "{query}\n",
    "\n",
    "Use ALL crime + news + cross-links below to generate a unified narrative:\n",
    "\n",
    "{context}\n",
    "\n",
    "Return a structured, factual narrative insight combining both datasets.\n",
    "\"\"\"\n",
    "\n",
    "        return self.model.generate_content(prompt).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe25db4400287196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T02:51:34.853515Z",
     "start_time": "2025-12-05T02:51:31.327883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing system...\n",
      "Data ready.\n",
      " Creating crime chunks → JSONL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1870768/1870768 [00:21<00:00, 86614.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime chunks saved.\n",
      " Creating news chunks → JSONL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15299/15299 [00:01<00:00, 13007.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News chunks saved.\n",
      "Building deterministic crime ↔ news links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1923226/1923226 [48:21<00:00, 662.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic links created.\n",
      "Building vector index: cache/crime_index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [00:04, 122.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved: cache/crime_index.faiss\n",
      "Building vector index: cache/news_index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15299it [03:06, 81.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved: cache/news_index.faiss\n",
      " Running Hybrid RAG Query...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on an analysis of the provided crime data, news reports, and cross-links, here is a unified narrative regarding robbery-related events near Lincoln Avenue this week.\\n\\n### Narrative Insight\\n\\nWhile official crime data for Lincoln Avenue this week specifies **theft**, not robbery, several violent **robberies** have been reported in adjacent North Side neighborhoods, including Lincoln Park, which Lincoln Avenue passes through. Analysis suggests a distinction between property crime on the avenue itself and more violent, person-to-person crime in the surrounding area.\\n\\n### Detailed Breakdown\\n\\n*   **Thefts on Lincoln Avenue:** Crime data from April 21, 2025, shows a cluster of five **theft** incidents on the **6100 block of North Lincoln Avenue**. One arrest was made in connection with these events. It is important to note these are classified as theft, which typically does not involve force or the threat of force against a victim.\\n\\n*   **Violent Robberies in Lincoln Park:** News reports from this week detail more severe robbery incidents in the nearby Lincoln Park neighborhood:\\n    *   A teacher was stalked and robbed in the afternoon as she walked to school. She fought off her attacker, who slammed her to the ground. The suspect, who allegedly hoped to steal her phone for $100, was later released on a $100 bond.\\n    *   A violent home invasion robbery occurred in the **400 block of West Fullerton Parkway**. Three men forced their way into a 32-year-old woman\\'s home, beat her, tied her up, and put tape over her mouth before stealing a computer, cellphone, and wallet.\\n\\n*   **Broader Robbery Pattern in the Area:** A related news report indicates a wider pattern of robberies on the North Side. A car connected to 16 armed robberies across the North and Northwest Sides was recovered on Monday in the Rogers Park neighborhood, near the northern terminus of Lincoln Avenue. Two juvenile suspects were taken into custody in that case.\\n\\n### Inconclusive or Unrelated Information\\n\\n*   The provided cross-links were analyzed but did not correlate with the specified crimes on or near Lincoln Avenue. The dates, locations, and crime types in the links were unrelated to this query.\\n*   News reports concerning robberies in Evanston and an armed robbery on Lincoln Highway in Frankfort were excluded, as they occurred outside the requested Chicago geography.\\n*   Crime reports from 2021 and 2022 on Randolph Street and Howard Street were excluded as they fall outside the \"this week\" timeframe.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = NarrativeIntelligenceSystem(crime_df, news_df)\n",
    "\n",
    "system.create_crime_chunks()\n",
    "system.create_news_chunks()\n",
    "system.build_crime_news_links(days_window=3)\n",
    "\n",
    "system.build_vector_index(CRIME_CHUNKS_FILE, f\"{CACHE_DIR}/crime_index.faiss\")\n",
    "system.build_vector_index(NEWS_CHUNKS_FILE, f\"{CACHE_DIR}/news_index.faiss\")\n",
    "\n",
    "chat = NarrativeChatbot(\"AIzaSyAwhy9oNOYiYUByyPZwFEYy_Q8p2GLUn_U\", system)\n",
    "\n",
    "chat.ask(\"What happened near Lincoln Ave related to robbery this week?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f2ef0d6732ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T22:17:00.319447Z",
     "start_time": "2025-12-03T22:16:33.898391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running Hybrid RAG Query...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on an analysis of the provided crime reports, news articles, and cross-links, there is no evidence that the specified criminal damage incidents were covered in the news.\n",
       "\n",
       "### Narrative Insight\n",
       "\n",
       "The available data presents two separate, unconnected narratives regarding crime in Chicago.\n",
       "\n",
       "**1. Unreported Criminal Damage Incidents:**\n",
       "Crime reports detail several incidents of \"CRIMINAL DAMAGE\" across the city between 2020 and 2025. Of the locations provided, only one falls within the Englewood neighborhood:\n",
       "*   **070XX S LOWE AVE** (Englewood)\n",
       "*   **070XX S BENNETT AVE** (South Shore)\n",
       "*   **091XX S LOWE AVE** (Washington Heights)\n",
       "*   **047XX S GREENWOOD AVE** (Kenwood)\n",
       "*   **027XX W LELAND AVE** (Lincoln Square)\n",
       "\n",
       "Despite multiple incidents at each location, none of these specific events are mentioned in the provided news articles or connected to them via the cross-links.\n",
       "\n",
       "**2. News Coverage Focused on Violent Crime in Englewood:**\n",
       "The supplied news articles exclusively cover severe violent crime—specifically shootings—in the Englewood and West Englewood neighborhoods. These reports detail multiple fatalities and injuries, police responses, and community reactions, including one instance where a police shooting in Englewood led to looting and property damage downtown on the Magnificent Mile. However, this coverage does not extend to the specific, smaller-scale criminal damage incidents listed in the crime data.\n",
       "\n",
       "**Conclusion:**\n",
       "The provided data indicates a clear separation between the types of crime that receive media attention and those that do not. While Englewood is the focus of intense news coverage for shootings and gun violence, the data shows no news reporting on the listed incidents of criminal damage in or near the neighborhood. The cross-links further confirm this disconnect, as they link other crimes to other news stories entirely, but do not establish any connection between the supplied criminal damage reports and the news articles on Englewood."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = NarrativeChatbot(\"AIzaSyAwhy9oNOYiYUByyPZwFEYy_Q8p2GLUn_U\", system)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown((chat.ask(\"Did any news articles cover the criminal damage incidents near Englewood?\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ace24172444c211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:23:11.140003Z",
     "start_time": "2025-12-03T23:22:50.668554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running Hybrid RAG Query...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on an analysis of the provided crime data, news reports, and cross-links, here is a unified narrative regarding crimes with arrests near the N. Lincoln Avenue corridor.\n",
       "\n",
       "### **Analysis of Crime on the N. Lincoln Avenue Corridor**\n",
       "\n",
       "The provided data points to two distinct criminal events with arrests occurring directly on North Lincoln Avenue.\n",
       "\n",
       "1.  **Violent Crime and SWAT Response in North Center:** A news report details a significant incident in the **4100 block of N. Lincoln Avenue**. On a Monday morning, a 74-year-old man was shot and critically wounded in the adjacent 2000 block of West Berteau Avenue. The subsequent police investigation led to a SWAT team establishing a perimeter at the corner of Berteau and Lincoln Avenues. According to Ald. Matt Martin (47th), **one arrest was made** in connection with the shooting, while a search for a second individual continues.\n",
       "\n",
       "2.  **Theft Incidents in West Ridge:** Further north, official crime data reports a series of five theft incidents on **April 21, 2025**, in the **6100 block of N. Lincoln Avenue**. This cluster of activity resulted in **one arrest**.\n",
       "\n",
       "### **Related Incidents in Adjacent Neighborhoods**\n",
       "\n",
       "Cross-links in the data suggest connections between crime reports in neighborhoods intersected by or near the Lincoln Avenue corridor and various news reports. However, these links do not confirm that the news articles are reporting on these specific crime instances or that arrests occurred in every case. Relevant incidents from these links include:\n",
       "\n",
       "*   **Criminal Sexual Assault:** A report was filed for an incident on the **3300 block of N. Damen Avenue** in North Center, a street in close proximity to Lincoln Avenue.\n",
       "*   **Theft:** Reports were also filed on the **2200 block of N. Racine Avenue** in Lincoln Park and the **3400 block of N. Clark Street** in Lakeview, both neighborhoods through which the Lincoln corridor runs.\n",
       "\n",
       "### **Geographically Unrelated Incidents with Arrests**\n",
       "\n",
       "To provide a complete picture of the supplied dataset, it is important to note that it also contains multiple crime reports with arrests that are geographically distant from the N. Lincoln Avenue corridor. These incidents are not part of a pattern related to the corridor itself.\n",
       "\n",
       "*   **West Side Thefts:** A significant number of arrests were made in connection with theft on West North Avenue. Reports from the **4600 and 4700 blocks of W. North Avenue** show a total of 15 theft incidents across three separate dates, leading to a combined **13 arrests**.\n",
       "*   **South Side Offenses:** In Englewood, a crime report from the **5800 block of S. Ada Street** documents 13 incidents classified as \"Other Offense,\" resulting in **6 arrests**.\n",
       "*   **Suburban Crime:** News reports detail numerous arrests made by police in the suburban communities of **Evanston** and **Park Ridge** for offenses including robbery, battery, drug possession, and DUI. These are separate jurisdictions and events from the Chicago-based data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown((chat.ask(\"What crimes with arrests were reported near the N Lincoln Ave corridor?\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db965c0ec6168be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:33:28.305014Z",
     "start_time": "2025-12-03T23:32:51.920825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running Hybrid RAG Query...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As a Chicago crime-narrative analyst, here is a structured insight into the effectiveness of police response in Englewood based on the provided data.\n",
       "\n",
       "### **Narrative Insight: Police Effectiveness in Englewood**\n",
       "\n",
       "Based on the supplied data, police response in Englewood is characterized by a complex mix of high-stakes engagement, strategic and equipment-related deficiencies, and inconsistent enforcement outcomes. While police are actively involved in volatile and dangerous situations within the neighborhood, the data points to systemic challenges that undermine overall effectiveness, particularly concerning accountability and follow-through on certain crime types.\n",
       "\n",
       "### **Analysis by Data Source**\n",
       "\n",
       "**1. Arrest Patterns & Enforcement Disparities**\n",
       "\n",
       "The crime data provided reveals a stark contrast in police effectiveness based on crime type and location, suggesting a targeted but narrow enforcement strategy.\n",
       "\n",
       "*   **Ineffectiveness in Property Crime:** For the crime of **Criminal Damage**, the data shows a 0% arrest rate across four separate locations and a total of 23 reported incidents. Two of these locations (070XX S Lowe Ave and 091XX S Lowe Ave) are within the Englewood/West Englewood area. This pattern indicates a systemic failure to resolve property crime cases, which can erode community trust and create an environment of impunity for lower-level offenses.\n",
       "*   **High Effectiveness in Targeted Operations:** In sharp contrast, a narcotics operation at 034XX W Chicago Ave (Humboldt Park, not Englewood) resulted in a 100% arrest rate, with 17 arrests for 17 incidents. While occurring outside the neighborhood in question, this demonstrates that when a specific crime type is targeted, the department can be highly effective. The disparity suggests that resources and strategic priorities are focused away from crimes like criminal damage.\n",
       "\n",
       "**2. News Reporting: A Focus on Crisis and Systemic Failures**\n",
       "\n",
       "News reports center on Englewood as a flashpoint for significant and often controversial police incidents, highlighting critical operational failures.\n",
       "\n",
       "*   **Equipment and Accountability Deficiencies:** Multiple articles detail the shooting of Latrell Allen in Englewood by a police officer who was not equipped with a body-worn camera. This officer was part of a newly formed \"hot spot\" unit deployed by Superintendent David Brown. Mayor Lori Lightfoot publicly acknowledged this as a systemic problem, citing contract issues and departmental reorganization. The absence of video evidence in such a critical incident erodes public trust and complicates the official narrative, directly contributing to civil unrest.\n",
       "*   **Volatile Environment and Violence Against Officers:** Police work in Englewood is portrayed as exceptionally dangerous. One report details two officers being shot in the neighborhood in less than a week during separate encounters, one of which was a traffic stop. This underscores the high-risk nature of police engagement in the area.\n",
       "*   **Inconsistent Strategic Command:** The response to public unrest shows further cracks. A report from the city's Inspector General highlights how a protest originating in Englewood following the death of George Floyd was a precursor to city-wide chaos that the Chicago Police Department was unprepared for and failed to control. This points to a failure in high-level strategic planning. Conversely, a report from a Fourth of July weekend notes that Englewood was \"quiet\" during a high-visibility patrol that included a ride-along with Mayor Lightfoot, suggesting that a concentrated police presence can have a temporary, localized deterrent effect.\n",
       "\n",
       "**3. Cross-Link Analysis**\n",
       "\n",
       "An analysis of the provided cross-links reveals that they are **not relevant** to the specific events, locations, or news reports concerning Englewood. The linked crimes and articles pertain to different neighborhoods (e.g., Portage Park, Lincoln Park), different topics (federal immigration agents, a 2004 cold case), and do not connect to the provided Englewood-centric data. Therefore, they offer no insight into police effectiveness within the Englewood neighborhood itself.\n",
       "\n",
       "### **Unified Narrative**\n",
       "\n",
       "The combined data paints a portrait of a police department that is heavily engaged in Englewood but struggles with effectiveness on multiple fronts. The narrative is not one of neglect, but of deeply flawed and inconsistent execution.\n",
       "\n",
       "Police presence in Englewood is defined by high-stakes, violent encounters—both initiated by and directed against officers. The creation of \"hot spot\" units shows a strategic intent to address crime, yet this strategy is immediately undermined by fundamental failures, such as deploying these units without essential accountability tools like body cameras. This single failure fueled significant public backlash.\n",
       "\n",
       "While officers face clear and present danger, the department's broader effectiveness is questionable. The complete absence of arrests for repeated instances of criminal damage in and around Englewood suggests that such crimes are not a priority, leaving residents to deal with neighborhood decay. This contrasts sharply with the department's demonstrated ability to conduct successful, high-arrest operations against narcotics elsewhere.\n",
       "\n",
       "Ultimately, police response in Englewood appears paradoxical: it is simultaneously intense and insufficient. Officers are on the front lines of violent confrontations, but the strategic and logistical support behind them is flawed, leading to failures in accountability, inconsistent crime resolution, and an inability to manage large-scale civil unrest originating within the neighborhood."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown((chat.ask(\"How effective has police response been in Englewood according to arrest patterns and news reporting?\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98cd41",
   "metadata": {},
   "source": [
    "## RAG-LLM EVALUATION METRICS\n",
    "### Comprehensive evaluation of retrieval quality and generation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a80f6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed RAG Evaluator loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class RAGEvaluator:\n",
    "    \"\"\"Comprehensive RAG-LLM evaluation metrics for NarrativeIntelligenceSystem.\"\"\"\n",
    "    \n",
    "    def __init__(self, system, chat):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            system: NarrativeIntelligenceSystem instance\n",
    "            chat: NarrativeChatbot instance\n",
    "        \"\"\"\n",
    "        self.system = system\n",
    "        self.chat = chat\n",
    "        \n",
    "    # ========== RETRIEVAL METRICS ==========\n",
    "    \n",
    "    def evaluate_retrieval_quality(self, query: str, top_k=5) -> Dict:\n",
    "        \"\"\"Evaluate quality of retrieved documents.\"\"\"\n",
    "        rag_results = self.system.rag_query(query, top_k=top_k)\n",
    "        \n",
    "        metrics = {\n",
    "            'crime_docs_retrieved': len(rag_results['crime']),\n",
    "            'news_docs_retrieved': len(rag_results['news']),\n",
    "            'links_found': len(rag_results['links']),\n",
    "            'total_retrieved': len(rag_results['crime']) + len(rag_results['news'])\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_retrieval_diversity(self, query: str, top_k=5) -> Dict:\n",
    "        \"\"\"Measure diversity of retrieved documents.\"\"\"\n",
    "        rag_results = self.system.rag_query(query, top_k=top_k)\n",
    "        \n",
    "        # Extract crime types from retrieved crime chunks\n",
    "        crime_types = []\n",
    "        for crime_doc in rag_results['crime']:\n",
    "            if crime_doc and 'text' in crime_doc:\n",
    "                # Parse crime type from text\n",
    "                match = re.search(r'Type:\\s*(.+)', crime_doc['text'])\n",
    "                if match:\n",
    "                    crime_types.append(match.group(1).strip())\n",
    "        \n",
    "        # Extract news titles\n",
    "        news_titles = []\n",
    "        for news_doc in rag_results['news']:\n",
    "            if news_doc and 'metadata' in news_doc:\n",
    "                news_titles.append(news_doc['metadata'].get('title', 'Unknown'))\n",
    "        \n",
    "        metrics = {\n",
    "            'unique_crime_types': len(set(crime_types)),\n",
    "            'total_crime_docs': len(crime_types),\n",
    "            'crime_diversity_ratio': len(set(crime_types)) / len(crime_types) if crime_types else 0,\n",
    "            'unique_news_articles': len(set(news_titles)),\n",
    "            'total_news_docs': len(news_titles),\n",
    "            'news_diversity_ratio': len(set(news_titles)) / len(news_titles) if news_titles else 0\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_retrieval_coverage(self, query: str, top_k=5) -> Dict:\n",
    "        \"\"\"Evaluate temporal and spatial coverage.\"\"\"\n",
    "        rag_results = self.system.rag_query(query, top_k=top_k)\n",
    "        \n",
    "        # Extract dates and locations from crime data\n",
    "        crime_dates = []\n",
    "        crime_blocks = []\n",
    "        \n",
    "        for crime_doc in rag_results['crime']:\n",
    "            if crime_doc and 'text' in crime_doc:\n",
    "                # Parse date\n",
    "                date_match = re.search(r'Date:\\s*(.+)', crime_doc['text'])\n",
    "                if date_match:\n",
    "                    crime_dates.append(date_match.group(1).strip())\n",
    "                \n",
    "                # Parse block\n",
    "                block_match = re.search(r'Block:\\s*(.+)', crime_doc['text'])\n",
    "                if block_match:\n",
    "                    crime_blocks.append(block_match.group(1).strip())\n",
    "        \n",
    "        # Extract news dates\n",
    "        news_dates = []\n",
    "        for news_doc in rag_results['news']:\n",
    "            if news_doc and 'metadata' in news_doc:\n",
    "                news_dates.append(news_doc['metadata'].get('date', 'Unknown'))\n",
    "        \n",
    "        metrics = {\n",
    "            'unique_crime_dates': len(set(crime_dates)),\n",
    "            'unique_crime_locations': len(set(crime_blocks)),\n",
    "            'unique_news_dates': len(set(news_dates)),\n",
    "            'temporal_coverage_days': len(set(crime_dates)),\n",
    "            'spatial_coverage_blocks': len(set(crime_blocks)),\n",
    "            'deterministic_links': len(rag_results['links'])\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    # ========== GENERATION METRICS ==========\n",
    "    \n",
    "    def evaluate_answer_quality(self, query: str, answer: str, rag_results: Dict) -> Dict:\n",
    "        \"\"\"Evaluate quality of generated answer.\"\"\"\n",
    "        \n",
    "        # 1. Answer length and structure\n",
    "        word_count = len(answer.split())\n",
    "        sentence_count = len([s for s in answer.split('.') if s.strip()])\n",
    "        avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0\n",
    "        \n",
    "        # 2. Information density - check for numbers/statistics\n",
    "        numbers = re.findall(r'\\b\\d+(?:\\.\\d+)?%?\\b', answer)\n",
    "        stats_density = len(numbers) / word_count if word_count > 0 else 0\n",
    "        \n",
    "        # 3. Source citation - check if answer mentions sources\n",
    "        citation_keywords = ['according to', 'based on', 'data shows', 'reported', 'article', \n",
    "                           'news', 'crime data', 'records indicate', 'analysis shows']\n",
    "        citations = sum(1 for keyword in citation_keywords if keyword.lower() in answer.lower())\n",
    "        \n",
    "        # 4. Specificity - mentions of locations, dates, crime types\n",
    "        locations = len(re.findall(r'\\b(?:block|avenue|street|ave|st|district|neighborhood)\\b', answer.lower()))\n",
    "        dates = len(re.findall(r'\\b\\d{4}\\b|\\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\\b', answer.lower()))\n",
    "        \n",
    "        # 5. Structure indicators\n",
    "        headers = len(re.findall(r'(?:^|\\n)#+\\s+|(?:^|\\n)\\*\\*[^*]+\\*\\*', answer))\n",
    "        lists = len(re.findall(r'(?:^|\\n)\\s*[-*•]\\s+', answer))\n",
    "        \n",
    "        metrics = {\n",
    "            'word_count': word_count,\n",
    "            'sentence_count': sentence_count,\n",
    "            'avg_sentence_length': round(avg_sentence_length, 2),\n",
    "            'statistics_mentioned': len(numbers),\n",
    "            'stats_density': round(stats_density, 4),\n",
    "            'citation_indicators': citations,\n",
    "            'location_mentions': locations,\n",
    "            'temporal_mentions': dates,\n",
    "            'has_structure': headers + lists > 0,\n",
    "            'specificity_score': round((locations + dates + len(numbers)) / word_count, 4) if word_count > 0 else 0\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_context_utilization(self, query: str, answer: str, rag_results: Dict) -> Dict:\n",
    "        \"\"\"Measure how well the answer uses retrieved context.\"\"\"\n",
    "        \n",
    "        answer_lower = answer.lower()\n",
    "        \n",
    "        # Extract key terms from retrieved crime documents\n",
    "        crime_terms_in_context = []\n",
    "        for crime_doc in rag_results['crime']:\n",
    "            if crime_doc and 'text' in crime_doc:\n",
    "                # Extract crime type\n",
    "                type_match = re.search(r'Type:\\s*(.+)', crime_doc['text'])\n",
    "                if type_match:\n",
    "                    crime_terms_in_context.append(type_match.group(1).strip().lower())\n",
    "                \n",
    "                # Extract block\n",
    "                block_match = re.search(r'Block:\\s*(.+)', crime_doc['text'])\n",
    "                if block_match:\n",
    "                    crime_terms_in_context.append(block_match.group(1).strip().lower())\n",
    "        \n",
    "        # Extract key terms from news\n",
    "        news_terms_in_context = []\n",
    "        for news_doc in rag_results['news']:\n",
    "            if news_doc and 'metadata' in news_doc:\n",
    "                title = news_doc['metadata'].get('title', '').lower()\n",
    "                # Extract meaningful words from title (>4 chars)\n",
    "                words = [w for w in title.split() if len(w) > 4]\n",
    "                news_terms_in_context.extend(words)\n",
    "        \n",
    "        # Check how many context terms appear in answer\n",
    "        crime_terms_used = sum(1 for term in crime_terms_in_context if term and term in answer_lower)\n",
    "        news_terms_used = sum(1 for term in news_terms_in_context if term and term in answer_lower)\n",
    "        \n",
    "        total_context_terms = len(crime_terms_in_context) + len(news_terms_in_context)\n",
    "        total_used = crime_terms_used + news_terms_used\n",
    "        \n",
    "        # Check if links were mentioned\n",
    "        links_mentioned = 'link' in answer_lower or 'connection' in answer_lower or 'related' in answer_lower\n",
    "        \n",
    "        metrics = {\n",
    "            'crime_context_terms_available': len(crime_terms_in_context),\n",
    "            'crime_context_terms_used': crime_terms_used,\n",
    "            'news_context_terms_available': len(news_terms_in_context),\n",
    "            'news_context_terms_used': news_terms_used,\n",
    "            'context_utilization_rate': round(total_used / total_context_terms, 4) if total_context_terms > 0 else 0,\n",
    "            'crime_sources_available': len(rag_results['crime']),\n",
    "            'news_sources_available': len(rag_results['news']),\n",
    "            'links_available': len(rag_results['links']),\n",
    "            'links_mentioned_in_answer': links_mentioned\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_faithfulness(self, answer: str, rag_results: Dict) -> Dict:\n",
    "        \"\"\"Check if answer statements are supported by retrieved documents.\"\"\"\n",
    "        \n",
    "        # Extract all retrieved text\n",
    "        all_context = []\n",
    "        \n",
    "        for crime_doc in rag_results['crime']:\n",
    "            if crime_doc and 'text' in crime_doc:\n",
    "                all_context.append(crime_doc['text'].lower())\n",
    "        \n",
    "        for news_doc in rag_results['news']:\n",
    "            if news_doc and 'text' in news_doc:\n",
    "                all_context.append(news_doc['text'].lower())\n",
    "        \n",
    "        combined_context = ' '.join(all_context)\n",
    "        \n",
    "        # Split answer into claims (sentences)\n",
    "        claims = [s.strip() for s in answer.split('.') if s.strip() and len(s.strip()) > 10]\n",
    "        \n",
    "        # Simple faithfulness check - are key terms from claims in context?\n",
    "        supported_claims = 0\n",
    "        for claim in claims:\n",
    "            # Extract key nouns/terms from claim (simple heuristic)\n",
    "            claim_words = [w.lower() for w in claim.split() if len(w) > 4 and w.isalpha()]\n",
    "            if claim_words:\n",
    "                # Check if at least 30% of key words appear in context\n",
    "                matches = sum(1 for word in claim_words if word in combined_context)\n",
    "                if matches / len(claim_words) >= 0.3:\n",
    "                    supported_claims += 1\n",
    "        \n",
    "        metrics = {\n",
    "            'total_claims': len(claims),\n",
    "            'supported_claims': supported_claims,\n",
    "            'faithfulness_score': round(supported_claims / len(claims), 4) if claims else 0,\n",
    "            'unsupported_claims': len(claims) - supported_claims,\n",
    "            'context_size_words': len(combined_context.split())\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    # ========== COMPREHENSIVE EVALUATION ==========\n",
    "    \n",
    "    def comprehensive_evaluation(self, query: str, top_k=5) -> Dict:\n",
    "        \"\"\"Run all evaluation metrics on a query.\"\"\"\n",
    "        \n",
    "        print(f\"Running comprehensive evaluation for query: '{query}'\")\n",
    "        print(f\"   Retrieving top {top_k} results...\\n\")\n",
    "        \n",
    "        # Get retrieval results\n",
    "        rag_results = self.system.rag_query(query, top_k=top_k)\n",
    "        \n",
    "        # Generate answer\n",
    "        print(\"   Generating answer...\")\n",
    "        answer = self.chat.ask(query)\n",
    "        \n",
    "        # Run all evaluations\n",
    "        eval_results = {\n",
    "            'query': query,\n",
    "            'answer': answer,\n",
    "            'retrieval_metrics': {\n",
    "                'quality': self.evaluate_retrieval_quality(query, top_k),\n",
    "                'diversity': self.evaluate_retrieval_diversity(query, top_k),\n",
    "                'coverage': self.evaluate_retrieval_coverage(query, top_k)\n",
    "            },\n",
    "            'generation_metrics': {\n",
    "                'answer_quality': self.evaluate_answer_quality(query, answer, rag_results),\n",
    "                'context_utilization': self.evaluate_context_utilization(query, answer, rag_results),\n",
    "                'faithfulness': self.evaluate_faithfulness(answer, rag_results)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return eval_results\n",
    "    \n",
    "    def print_evaluation_report(self, eval_results: Dict):\n",
    "        \"\"\"Print a formatted evaluation report.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RAG-LLM EVALUATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nQuery: {eval_results['query']}\")\n",
    "        \n",
    "        # Retrieval Metrics\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"RETRIEVAL METRICS\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        qual = eval_results['retrieval_metrics']['quality']\n",
    "        print(f\"\\n  Quality:\")\n",
    "        print(f\"    • Crime Documents Retrieved: {qual['crime_docs_retrieved']}\")\n",
    "        print(f\"    • News Documents Retrieved: {qual['news_docs_retrieved']}\")\n",
    "        print(f\"    • Deterministic Links Found: {qual['links_found']}\")\n",
    "        print(f\"    • Total Documents: {qual['total_retrieved']}\")\n",
    "        \n",
    "        div = eval_results['retrieval_metrics']['diversity']\n",
    "        print(f\"\\n  Diversity:\")\n",
    "        print(f\"    • Unique Crime Types: {div['unique_crime_types']} / {div['total_crime_docs']}\")\n",
    "        print(f\"    • Crime Diversity Ratio: {div['crime_diversity_ratio']:.2%}\")\n",
    "        print(f\"    • Unique News Articles: {div['unique_news_articles']} / {div['total_news_docs']}\")\n",
    "        print(f\"    • News Diversity Ratio: {div['news_diversity_ratio']:.2%}\")\n",
    "        \n",
    "        cov = eval_results['retrieval_metrics']['coverage']\n",
    "        print(f\"\\n  Coverage:\")\n",
    "        print(f\"    • Unique Crime Dates: {cov['unique_crime_dates']}\")\n",
    "        print(f\"    • Unique Crime Locations: {cov['unique_crime_locations']}\")\n",
    "        print(f\"    • Temporal Coverage: {cov['temporal_coverage_days']} days\")\n",
    "        print(f\"    • Spatial Coverage: {cov['spatial_coverage_blocks']} blocks\")\n",
    "        \n",
    "        # Generation Metrics\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"GENERATION METRICS\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        ans_qual = eval_results['generation_metrics']['answer_quality']\n",
    "        print(f\"\\n  Answer Quality:\")\n",
    "        print(f\"    • Word Count: {ans_qual['word_count']}\")\n",
    "        print(f\"    • Sentence Count: {ans_qual['sentence_count']}\")\n",
    "        print(f\"    • Avg Sentence Length: {ans_qual['avg_sentence_length']:.1f} words\")\n",
    "        print(f\"    • Statistics Mentioned: {ans_qual['statistics_mentioned']}\")\n",
    "        print(f\"    • Citation Indicators: {ans_qual['citation_indicators']}\")\n",
    "        print(f\"    • Location Mentions: {ans_qual['location_mentions']}\")\n",
    "        print(f\"    • Temporal Mentions: {ans_qual['temporal_mentions']}\")\n",
    "        print(f\"    • Has Structure: {'Yes' if ans_qual['has_structure'] else 'No'}\")\n",
    "        print(f\"    • Specificity Score: {ans_qual['specificity_score']:.4f}\")\n",
    "        \n",
    "        util = eval_results['generation_metrics']['context_utilization']\n",
    "        print(f\"\\n  Context Utilization:\")\n",
    "        print(f\"    • Crime Terms Used: {util['crime_context_terms_used']} / {util['crime_context_terms_available']}\")\n",
    "        print(f\"    • News Terms Used: {util['news_context_terms_used']} / {util['news_context_terms_available']}\")\n",
    "        print(f\"    • Overall Utilization Rate: {util['context_utilization_rate']:.2%}\")\n",
    "        print(f\"    • Sources Available: {util['crime_sources_available']} crime, {util['news_sources_available']} news, {util['links_available']} links\")\n",
    "        print(f\"    • Links Mentioned: {'Yes' if util['links_mentioned_in_answer'] else 'No'}\")\n",
    "        \n",
    "        faith = eval_results['generation_metrics']['faithfulness']\n",
    "        print(f\"\\n  Faithfulness:\")\n",
    "        print(f\"    • Total Claims: {faith['total_claims']}\")\n",
    "        print(f\"    • Supported Claims: {faith['supported_claims']}\")\n",
    "        print(f\"    • Faithfulness Score: {faith['faithfulness_score']:.2%}\")\n",
    "        print(f\"    • Unsupported Claims: {faith['unsupported_claims']}\")\n",
    "        print(f\"    • Context Size: {faith['context_size_words']:,} words\")\n",
    "        \n",
    "        # Overall Assessment\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\" OVERALL ASSESSMENT\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Calculate aggregate score - FIXED VERSION\n",
    "        ret_qual = eval_results['retrieval_metrics']['quality']\n",
    "        ret_div = eval_results['retrieval_metrics']['diversity']\n",
    "        ans_qual = eval_results['generation_metrics']['answer_quality']\n",
    "        ans_util = eval_results['generation_metrics']['context_utilization']\n",
    "        ans_faith = eval_results['generation_metrics']['faithfulness']\n",
    "        \n",
    "        retrieval_score = min(ret_qual['total_retrieved'] / 10, 1.0)  # Normalize to 0-1\n",
    "        diversity_score = (ret_div['crime_diversity_ratio'] + ret_div['news_diversity_ratio']) / 2\n",
    "        answer_quality_score = min(ans_qual['specificity_score'] * 50, 1.0)  # Normalize\n",
    "        utilization_score = ans_util['context_utilization_rate']\n",
    "        faithfulness_score = ans_faith['faithfulness_score']\n",
    "        \n",
    "        scores = {\n",
    "            'Retrieval Volume': retrieval_score,\n",
    "            'Retrieval Diversity': diversity_score,\n",
    "            'Answer Quality': answer_quality_score,\n",
    "            'Context Usage': utilization_score,\n",
    "            'Faithfulness': faithfulness_score\n",
    "        }\n",
    "        \n",
    "        for metric, score in scores.items():\n",
    "            bar = \"█\" * int(score * 20) + \"░\" * (20 - int(score * 20))\n",
    "            print(f\"  {metric:20} {bar} {score:.2%}\")\n",
    "        \n",
    "        overall_score = np.mean(list(scores.values()))\n",
    "        print(f\"\\n  Overall RAG Score: {overall_score:.2%}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "print(\"Fixed RAG Evaluator loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "989d6d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RAG Evaluator initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = RAGEvaluator(system, chat)\n",
    "print(\" RAG Evaluator initialized and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b821b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running comprehensive evaluation for query: 'What are the main public safety concerns in Englewood?'\n",
      "   Retrieving top 5 results...\n",
      "\n",
      " Running Hybrid RAG Query...\n",
      "   Generating answer...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      "\n",
      "================================================================================\n",
      "RAG-LLM EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "Query: What are the main public safety concerns in Englewood?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RETRIEVAL METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Quality:\n",
      "    • Crime Documents Retrieved: 5\n",
      "    • News Documents Retrieved: 5\n",
      "    • Deterministic Links Found: 20\n",
      "    • Total Documents: 10\n",
      "\n",
      "  Diversity:\n",
      "    • Unique Crime Types: 1 / 5\n",
      "    • Crime Diversity Ratio: 20.00%\n",
      "    • Unique News Articles: 5 / 5\n",
      "    • News Diversity Ratio: 100.00%\n",
      "\n",
      "  Coverage:\n",
      "    • Unique Crime Dates: 5\n",
      "    • Unique Crime Locations: 5\n",
      "    • Temporal Coverage: 5 days\n",
      "    • Spatial Coverage: 5 blocks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Answer Quality:\n",
      "    • Word Count: 432\n",
      "    • Sentence Count: 18\n",
      "    • Avg Sentence Length: 24.0 words\n",
      "    • Statistics Mentioned: 1\n",
      "    • Citation Indicators: 3\n",
      "    • Location Mentions: 7\n",
      "    • Temporal Mentions: 2\n",
      "    • Has Structure: Yes\n",
      "    • Specificity Score: 0.0231\n",
      "\n",
      "  Context Utilization:\n",
      "    • Crime Terms Used: 6 / 10\n",
      "    • News Terms Used: 20 / 46\n",
      "    • Overall Utilization Rate: 46.43%\n",
      "    • Sources Available: 5 crime, 5 news, 20 links\n",
      "    • Links Mentioned: Yes\n",
      "\n",
      "  Faithfulness:\n",
      "    • Total Claims: 18\n",
      "    • Supported Claims: 16\n",
      "    • Faithfulness Score: 88.89%\n",
      "    • Unsupported Claims: 2\n",
      "    • Context Size: 1,343 words\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " OVERALL ASSESSMENT\n",
      "--------------------------------------------------------------------------------\n",
      "  Retrieval Volume     ████████████████████ 100.00%\n",
      "  Retrieval Diversity  ████████████░░░░░░░░ 60.00%\n",
      "  Answer Quality       ████████████████████ 100.00%\n",
      "  Context Usage        █████████░░░░░░░░░░░ 46.43%\n",
      "  Faithfulness         █████████████████░░░ 88.89%\n",
      "\n",
      "  Overall RAG Score: 79.06%\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run comprehensive evaluation on a single query\n",
    "test_query = \"What are the main public safety concerns in Englewood?\"\n",
    "\n",
    "eval_results = evaluator.comprehensive_evaluation(\n",
    "    query=test_query,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# Print detailed report\n",
    "evaluator.print_evaluation_report(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24ad03ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running batch evaluation...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query 1/3\n",
      "================================================================================\n",
      "Running comprehensive evaluation for query: 'What crimes with arrests were reported near the N Lincoln Ave corridor?'\n",
      "   Retrieving top 3 results...\n",
      "\n",
      " Running Hybrid RAG Query...\n",
      "   Generating answer...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      "\n",
      "================================================================================\n",
      "RAG-LLM EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "Query: What crimes with arrests were reported near the N Lincoln Ave corridor?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RETRIEVAL METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Quality:\n",
      "    • Crime Documents Retrieved: 3\n",
      "    • News Documents Retrieved: 3\n",
      "    • Deterministic Links Found: 20\n",
      "    • Total Documents: 6\n",
      "\n",
      "  Diversity:\n",
      "    • Unique Crime Types: 1 / 3\n",
      "    • Crime Diversity Ratio: 33.33%\n",
      "    • Unique News Articles: 3 / 3\n",
      "    • News Diversity Ratio: 100.00%\n",
      "\n",
      "  Coverage:\n",
      "    • Unique Crime Dates: 3\n",
      "    • Unique Crime Locations: 3\n",
      "    • Temporal Coverage: 3 days\n",
      "    • Spatial Coverage: 3 blocks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Answer Quality:\n",
      "    • Word Count: 414\n",
      "    • Sentence Count: 22\n",
      "    • Avg Sentence Length: 18.8 words\n",
      "    • Statistics Mentioned: 8\n",
      "    • Citation Indicators: 7\n",
      "    • Location Mentions: 19\n",
      "    • Temporal Mentions: 5\n",
      "    • Has Structure: Yes\n",
      "    • Specificity Score: 0.0773\n",
      "\n",
      "  Context Utilization:\n",
      "    • Crime Terms Used: 3 / 6\n",
      "    • News Terms Used: 13 / 22\n",
      "    • Overall Utilization Rate: 57.14%\n",
      "    • Sources Available: 3 crime, 3 news, 20 links\n",
      "    • Links Mentioned: Yes\n",
      "\n",
      "  Faithfulness:\n",
      "    • Total Claims: 20\n",
      "    • Supported Claims: 15\n",
      "    • Faithfulness Score: 75.00%\n",
      "    • Unsupported Claims: 5\n",
      "    • Context Size: 845 words\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " OVERALL ASSESSMENT\n",
      "--------------------------------------------------------------------------------\n",
      "  Retrieval Volume     ████████████░░░░░░░░ 60.00%\n",
      "  Retrieval Diversity  █████████████░░░░░░░ 66.67%\n",
      "  Answer Quality       ████████████████████ 100.00%\n",
      "  Context Usage        ███████████░░░░░░░░░ 57.14%\n",
      "  Faithfulness         ███████████████░░░░░ 75.00%\n",
      "\n",
      "  Overall RAG Score: 71.76%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query 2/3\n",
      "================================================================================\n",
      "Running comprehensive evaluation for query: 'How effective has police response been in Englewood according to arrest patterns?'\n",
      "   Retrieving top 3 results...\n",
      "\n",
      " Running Hybrid RAG Query...\n",
      "   Generating answer...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      "\n",
      "================================================================================\n",
      "RAG-LLM EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "Query: How effective has police response been in Englewood according to arrest patterns?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RETRIEVAL METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Quality:\n",
      "    • Crime Documents Retrieved: 3\n",
      "    • News Documents Retrieved: 3\n",
      "    • Deterministic Links Found: 20\n",
      "    • Total Documents: 6\n",
      "\n",
      "  Diversity:\n",
      "    • Unique Crime Types: 2 / 3\n",
      "    • Crime Diversity Ratio: 66.67%\n",
      "    • Unique News Articles: 3 / 3\n",
      "    • News Diversity Ratio: 100.00%\n",
      "\n",
      "  Coverage:\n",
      "    • Unique Crime Dates: 3\n",
      "    • Unique Crime Locations: 3\n",
      "    • Temporal Coverage: 3 days\n",
      "    • Spatial Coverage: 3 blocks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Answer Quality:\n",
      "    • Word Count: 696\n",
      "    • Sentence Count: 29\n",
      "    • Avg Sentence Length: 24.0 words\n",
      "    • Statistics Mentioned: 11\n",
      "    • Citation Indicators: 6\n",
      "    • Location Mentions: 14\n",
      "    • Temporal Mentions: 5\n",
      "    • Has Structure: Yes\n",
      "    • Specificity Score: 0.0431\n",
      "\n",
      "  Context Utilization:\n",
      "    • Crime Terms Used: 3 / 6\n",
      "    • News Terms Used: 11 / 20\n",
      "    • Overall Utilization Rate: 53.85%\n",
      "    • Sources Available: 3 crime, 3 news, 20 links\n",
      "    • Links Mentioned: Yes\n",
      "\n",
      "  Faithfulness:\n",
      "    • Total Claims: 25\n",
      "    • Supported Claims: 14\n",
      "    • Faithfulness Score: 56.00%\n",
      "    • Unsupported Claims: 11\n",
      "    • Context Size: 832 words\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " OVERALL ASSESSMENT\n",
      "--------------------------------------------------------------------------------\n",
      "  Retrieval Volume     ████████████░░░░░░░░ 60.00%\n",
      "  Retrieval Diversity  ████████████████░░░░ 83.33%\n",
      "  Answer Quality       ████████████████████ 100.00%\n",
      "  Context Usage        ██████████░░░░░░░░░░ 53.85%\n",
      "  Faithfulness         ███████████░░░░░░░░░ 56.00%\n",
      "\n",
      "  Overall RAG Score: 70.64%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query 3/3\n",
      "================================================================================\n",
      "Running comprehensive evaluation for query: 'Were any criminal damage incidents near Englewood covered by news?'\n",
      "   Retrieving top 3 results...\n",
      "\n",
      " Running Hybrid RAG Query...\n",
      "   Generating answer...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      "\n",
      "================================================================================\n",
      "RAG-LLM EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "Query: Were any criminal damage incidents near Englewood covered by news?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RETRIEVAL METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Quality:\n",
      "    • Crime Documents Retrieved: 3\n",
      "    • News Documents Retrieved: 3\n",
      "    • Deterministic Links Found: 20\n",
      "    • Total Documents: 6\n",
      "\n",
      "  Diversity:\n",
      "    • Unique Crime Types: 1 / 3\n",
      "    • Crime Diversity Ratio: 33.33%\n",
      "    • Unique News Articles: 3 / 3\n",
      "    • News Diversity Ratio: 100.00%\n",
      "\n",
      "  Coverage:\n",
      "    • Unique Crime Dates: 3\n",
      "    • Unique Crime Locations: 3\n",
      "    • Temporal Coverage: 3 days\n",
      "    • Spatial Coverage: 3 blocks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Answer Quality:\n",
      "    • Word Count: 495\n",
      "    • Sentence Count: 22\n",
      "    • Avg Sentence Length: 22.5 words\n",
      "    • Statistics Mentioned: 4\n",
      "    • Citation Indicators: 4\n",
      "    • Location Mentions: 15\n",
      "    • Temporal Mentions: 1\n",
      "    • Has Structure: Yes\n",
      "    • Specificity Score: 0.0404\n",
      "\n",
      "  Context Utilization:\n",
      "    • Crime Terms Used: 6 / 6\n",
      "    • News Terms Used: 15 / 26\n",
      "    • Overall Utilization Rate: 65.62%\n",
      "    • Sources Available: 3 crime, 3 news, 20 links\n",
      "    • Links Mentioned: Yes\n",
      "\n",
      "  Faithfulness:\n",
      "    • Total Claims: 20\n",
      "    • Supported Claims: 12\n",
      "    • Faithfulness Score: 60.00%\n",
      "    • Unsupported Claims: 8\n",
      "    • Context Size: 816 words\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " OVERALL ASSESSMENT\n",
      "--------------------------------------------------------------------------------\n",
      "  Retrieval Volume     ████████████░░░░░░░░ 60.00%\n",
      "  Retrieval Diversity  █████████████░░░░░░░ 66.67%\n",
      "  Answer Quality       ████████████████████ 100.00%\n",
      "  Context Usage        █████████████░░░░░░░ 65.62%\n",
      "  Faithfulness         ████████████░░░░░░░░ 60.00%\n",
      "\n",
      "  Overall RAG Score: 70.46%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      " AGGREGATE STATISTICS ACROSS ALL QUERIES\n",
      "================================================================================\n",
      "\n",
      "  Average Documents Retrieved: 6.0\n",
      "  Average Faithfulness Score: 63.67%\n",
      "  Average Context Utilization: 58.87%\n",
      "  Average Answer Length: 535 words\n",
      "\n",
      "  Total Queries Evaluated: 3\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Batch evaluation on multiple queries\n",
    "test_queries = [\n",
    "    \"What crimes with arrests were reported near the N Lincoln Ave corridor?\",\n",
    "    \"How effective has police response been in Englewood according to arrest patterns?\",\n",
    "    \"Were any criminal damage incidents near Englewood covered by news?\"\n",
    "]\n",
    "\n",
    "print(\" Running batch evaluation...\\n\")\n",
    "\n",
    "batch_results = []\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query {i}/{len(test_queries)}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    result = evaluator.comprehensive_evaluation(query, top_k=3)\n",
    "    batch_results.append(result)\n",
    "    evaluator.print_evaluation_report(result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print()\n",
    "\n",
    "# Aggregate statistics\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\" AGGREGATE STATISTICS ACROSS ALL QUERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "avg_retrieval_volume = np.mean([r['retrieval_metrics']['quality']['total_retrieved'] for r in batch_results])\n",
    "avg_faithfulness = np.mean([r['generation_metrics']['faithfulness']['faithfulness_score'] for r in batch_results])\n",
    "avg_utilization = np.mean([r['generation_metrics']['context_utilization']['context_utilization_rate'] for r in batch_results])\n",
    "avg_word_count = np.mean([r['generation_metrics']['answer_quality']['word_count'] for r in batch_results])\n",
    "\n",
    "print(f\"\\n  Average Documents Retrieved: {avg_retrieval_volume:.1f}\")\n",
    "print(f\"  Average Faithfulness Score: {avg_faithfulness:.2%}\")\n",
    "print(f\"  Average Context Utilization: {avg_utilization:.2%}\")\n",
    "print(f\"  Average Answer Length: {avg_word_count:.0f} words\")\n",
    "print(f\"\\n  Total Queries Evaluated: {len(batch_results)}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a770d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: What happened near Lincoln Ave related to robbery this week?\n",
      "\n",
      "Running comprehensive evaluation for query: 'What happened near Lincoln Ave related to robbery this week?'\n",
      "   Retrieving top 5 results...\n",
      "\n",
      " Running Hybrid RAG Query...\n",
      "   Generating answer...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      " Running Hybrid RAG Query...\n",
      "\n",
      "================================================================================\n",
      "GENERATED ANSWER\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on an analysis of the provided crime data and news reports, here is a unified narrative regarding robbery-related incidents near Lincoln Avenue this week.\n",
       "\n",
       "**Direct Incident on Lincoln Avenue:**\n",
       "\n",
       "According to official crime data, there was a cluster of **thefts**, not robberies, on **Monday, April 21, 2025**. Five separate theft incidents were reported on the **6100 block of North Lincoln Avenue**. In connection with these events, one arrest has been made. The data does not specify the nature of these thefts or if they were related.\n",
       "\n",
       "**Broader Context from Regional News:**\n",
       "\n",
       "While the specific incidents on Lincoln Avenue were classified as theft, several significant **robberies** have occurred recently in similarly named or nearby locations, which contributes to the public safety narrative in the area:\n",
       "\n",
       "*   **Lincoln Park Neighborhood Robbery:** A high-profile robbery occurred last week in the Lincoln Park neighborhood where a young teacher was stalked, attacked, and slammed to the ground in the afternoon. Her attacker, who allegedly hoped to steal her phone for $100, was released on a $100 bond, causing public outcry from the victim's family.\n",
       "*   **Lincoln Park Home Invasion:** In a separate, violent incident this week, a woman was beaten, tied up, and had her mouth taped by three men during a home invasion robbery in the Lincoln Park neighborhood, on the 400 block of West Fullerton Parkway.\n",
       "*   **Lincoln Highway Armed Robbery (Clarification):** An armed robbery at Ryan's Pub occurred in Frankfort Township on Lincoln Highway, a distinct location from Chicago's Lincoln Avenue. This incident resulted in one of the alleged offenders being fatally shot by a patron. Two other suspects have since been charged.\n",
       "\n",
       "**Summary Narrative:**\n",
       "\n",
       "This week's primary police activity on Lincoln Avenue itself involved five reported thefts on the North Side, leading to one arrest. However, the broader public concern about robbery is likely fueled by recent, more violent crimes in the nearby Lincoln Park neighborhood, including the widely reported attack on a teacher and a brutal home invasion. It is important to distinguish the specific theft reports on North Lincoln Avenue from these other robbery incidents and to note that the armed robbery at Ryan's Pub occurred on Lincoln Highway in a different municipality.\n",
       "\n",
       "The provided cross-links did not contain any connections between these specific crime reports and news articles."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "RAG-LLM EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "Query: What happened near Lincoln Ave related to robbery this week?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RETRIEVAL METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Quality:\n",
      "    • Crime Documents Retrieved: 5\n",
      "    • News Documents Retrieved: 5\n",
      "    • Deterministic Links Found: 20\n",
      "    • Total Documents: 10\n",
      "\n",
      "  Diversity:\n",
      "    • Unique Crime Types: 1 / 5\n",
      "    • Crime Diversity Ratio: 20.00%\n",
      "    • Unique News Articles: 5 / 5\n",
      "    • News Diversity Ratio: 100.00%\n",
      "\n",
      "  Coverage:\n",
      "    • Unique Crime Dates: 5\n",
      "    • Unique Crime Locations: 3\n",
      "    • Temporal Coverage: 5 days\n",
      "    • Spatial Coverage: 3 blocks\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Answer Quality:\n",
      "    • Word Count: 381\n",
      "    • Sentence Count: 15\n",
      "    • Avg Sentence Length: 25.4 words\n",
      "    • Statistics Mentioned: 6\n",
      "    • Citation Indicators: 6\n",
      "    • Location Mentions: 13\n",
      "    • Temporal Mentions: 3\n",
      "    • Has Structure: Yes\n",
      "    • Specificity Score: 0.0577\n",
      "\n",
      "  Context Utilization:\n",
      "    • Crime Terms Used: 5 / 10\n",
      "    • News Terms Used: 21 / 39\n",
      "    • Overall Utilization Rate: 53.06%\n",
      "    • Sources Available: 5 crime, 5 news, 20 links\n",
      "    • Links Mentioned: Yes\n",
      "\n",
      "  Faithfulness:\n",
      "    • Total Claims: 15\n",
      "    • Supported Claims: 14\n",
      "    • Faithfulness Score: 93.33%\n",
      "    • Unsupported Claims: 1\n",
      "    • Context Size: 1,387 words\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " OVERALL ASSESSMENT\n",
      "--------------------------------------------------------------------------------\n",
      "  Retrieval Volume     ████████████████████ 100.00%\n",
      "  Retrieval Diversity  ████████████░░░░░░░░ 60.00%\n",
      "  Answer Quality       ████████████████████ 100.00%\n",
      "  Context Usage        ██████████░░░░░░░░░░ 53.06%\n",
      "  Faithfulness         ██████████████████░░ 93.33%\n",
      "\n",
      "  Overall RAG Score: 81.28%\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your own custom query\n",
    "from IPython.display import Markdown\n",
    "\n",
    "custom_query = \"What happened near Lincoln Ave related to robbery this week?\"\n",
    "\n",
    "print(f\"Evaluating: {custom_query}\\n\")\n",
    "result = evaluator.comprehensive_evaluation(custom_query, top_k=5)\n",
    "\n",
    "# Show the answer\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED ANSWER\")\n",
    "print(\"=\"*80)\n",
    "display(Markdown(result['answer']))\n",
    "\n",
    "# Show metrics\n",
    "print()\n",
    "evaluator.print_evaluation_report(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (RAG)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
